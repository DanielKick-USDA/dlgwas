#| default_exp kegg

#| hide
# from nbdev.showdoc import *

import os
import tqdm
from tqdm import tqdm
import re
import time
import sys
import requests
import numpy as np
import pandas as pd
import plotly.express as px

#| export

"Iteratively check for and create directories to store output. Ideally this would just be os.mkdirs() but that function is not available in this version of python"
def ensure_dir_path_exists(dir_path = '../ext_data'):
    import os
    
    for i in range(2, len(dir_path.split('/'))+1):
        path_part = '/'.join(dir_path.split('/')[0:i])
        if not os.path.exists(path_part):
            os.mkdir(path_part)
        

#| export

"Retrieve a previously calculated result. Return None if it cannot be found."
def get_cached_result(
    save_path
):
    import os
    import pickle as pkl
    if not os.path.exists(save_path):
        cached_result = None
    else:
        with open(save_path, 'rb') as handle:
                cached_result = pkl.load(handle)
    return(cached_result)

#| export

def put_cached_result(
    save_path,
    save_obj
):
    import pickle as pkl
    from dlgwas.kegg import ensure_dir_path_exists
    ensure_dir_path_exists(dir_path= '/'.join(save_path.split('/')[:-1]) )
    
    with open(save_path, 'wb') as handle:
            pkl.dump(save_obj, 
                     handle, 
                     protocol=pkl.HIGHEST_PROTOCOL)



# # This is the expected boiler plate for using the above functions. 

# save_path = './demofile.txt'

# demo = get_cached_result(save_path=save_path)

# if None == samples_and_matches:
#     demo = CODE TO MAKE DEMO HERE
    
#     put_cached_result(
#         save_path = save_path,
#         save_obj = demo
#     )




#| export

# Get all the genes for zea mays
# Some gene entries that don't start begin with a chromosome number. These included plastid (Pltd) and mitochondria (MT) genes.

def get_kegg_species_list(species = 'zma'):
    import os
    import requests
    # make sure the directory exists to hold these data
    ensure_dir_path_exists(dir_path = '../ext_data/'+species+'/kegg')

    file_path = '../ext_data/'+species+'/kegg'+'/'+species+'_list.txt'
    # only retrieve if there isn't a local copy
    if file_path.split('/')[-1] in os.listdir('/'.join(file_path.split('/')[:-1])):
        with open(file_path, 'r') as f:
            r_text = f.read()
    else:
        r = requests.get('https://rest.kegg.jp/list/'+species)
        r_text = r.text
        with open(file_path, 'a') as f:
            f.write(r_text)
    return(r_text)

#| export
def mkdf_kegg_species_list(kegg_species_list):
    import pandas as pd
    kegg_list_zma = pd.DataFrame([e.split('\t') for e in kegg_species_list.split('\n') ])
    # clean up names
    kegg_list_zma = kegg_list_zma.rename(columns = dict(zip(
        [i for i in range(4)],
        ['gene', 'seq_type', 'chromosome_positon', 'gene_type']
    )))

    kegg_list_zma = kegg_list_zma.loc[kegg_list_zma.chromosome_positon.notna(), ]
    return(kegg_list_zma)

kegg_zma_list = get_kegg_species_list(species = 'zma')
kegg_list_zma = mkdf_kegg_species_list(kegg_species_list = kegg_zma_list)

no_chrm = [e for e in kegg_list_zma['chromosome_positon'] if re.match('\D.+', e)]
no_chrm = list(set(no_chrm))
kegg_list_zma.loc[kegg_list_zma.chromosome_positon.isin(no_chrm), ]

#| export

def download_kegg_gene(kegg_gene = 'zma:103644366', **kwargs):    
    """
    Downloads kegg gene entry if it does not exist locally. 
    Can optionally take a numeric value as `sleep_for` to sleep after downloading a file. 
    Useful for controlling the rate requests being sent to the API.
    """
    species = kegg_gene.split(':')[0]
    dir_path = '../ext_data/'+species+'/kegg/gene_entries/'
    ensure_dir_path_exists(dir_path = dir_path)
    
    kegg_gene_safename = kegg_gene.replace(':', '_') # name that's safe for file names
    file_path = dir_path+kegg_gene_safename+'.txt'
    
    # only download if the file doesn't already exist
    if os.path.exists(file_path):
        pass
    else:
        # option to sleep for a given amount of time so tha tthe api isn't accessed to much
        # sleeping here means that we only sleep if there will be a request to download
        if 'sleep_for' in kwargs.keys():
            time.sleep(kwargs['sleep_for'])
        
        r = requests.get('https://rest.kegg.jp/get/'+kegg_gene)
        with open(file_path, 'a') as f:
            f.write(r.text)

#| export
def read_kegg_gene(
    kegg_gene = 'zma:103644366',
    **kwargs # Intended to allow for explicit 'encoding' to be passed into open the file : encoding="ISO-8859-1"
    ):  
    "Reads in locally cached KEGG gene entries. Will download the requested entry if it doesn't exist locally."
    import os
    species = kegg_gene.split(':')[0]
    dir_path = '../ext_data/'+species+'/kegg/gene_entries/'
    ensure_dir_path_exists(dir_path = dir_path)
    
    kegg_gene_safename = kegg_gene.replace(':', '_') # name that's safe for file names
    file_path = dir_path+kegg_gene_safename+'.txt'

    if not os.path.exists(file_path):
        download_kegg_gene(kegg_gene)
    
    if 'encoding' in kwargs.keys():
        with open(file_path, encoding  = kwargs['encoding']) as f:
            r_text = f.read()        
    else:
        with open(file_path) as f:
            r_text = f.read()
            
    return(r_text)

print(read_kegg_gene(kegg_gene = 'zma:103644366'))

for kegg_gene in tqdm(kegg_list_zma.gene):
    try:
        download_kegg_gene(kegg_gene = kegg_gene, 
                           sleep_for = np.random.uniform(0.5, 1.5))
    except:
        print('Problem with '+kegg_gene) 

# # import tqdm
# import os, re
import pickle as pkl

# import dlgwas
# from dlgwas.core import *

kegg_zma_list = get_kegg_species_list(species = 'zma')

kegg_zma_list = get_kegg_species_list(species = 'zma')

kegg_list_zma = mkdf_kegg_species_list(kegg_species_list = kegg_zma_list)

kegg_list_zma.head()

kegg_file = 'zma_100125650.txt'
# convert back to KEGG format
kegg_gene_name = kegg_file.replace('_', ':').replace('.txt', '')

# convert back to kegg format
r_text = read_kegg_gene(kegg_gene = kegg_gene_name)

# parsing gene entry
r_text_list = r_text.split('\n')
r_text_list[0:5]

# Some files may not contain all sections so this list needs to be created for each file
section_names = [r_text_list[i][0:12].strip() for i in range(len(r_text_list)) ]
section_names = [e for e in section_names if e != '']

section_starts = [
    [i for i in range(len(r_text_list)) if re.match('^'+e, r_text_list[i])][0] 
    for e in section_names]

section_names, section_starts

# just split each file into text of it's sections
out = {}

# get lines associated with section
def _get_section_text(section_name = 'AASEQ'):
    idx = section_names.index(section_name)
    section_text = r_text_list[section_starts[idx]:section_starts[idx+1]]
    # remove leading indent
    section_text = [e[12:] for e in section_text]
    return(section_text)

for section_name in section_names:
    if section_name != '///': # end of file
        out[section_name] = _get_section_text(section_name = section_name)

out

def kegg_gene_to_dict(kegg_file = 'zma_100125650.txt',
                     **kwargs):
    # convert back to kegg format
    if 'encoding' in kwargs.keys():
        r_text = read_kegg_gene(
            kegg_gene= kegg_file.replace('_', ':').replace('.txt', ''),
            encoding  = kwargs['encoding']
        )
    else:
        r_text = read_kegg_gene(
            kegg_gene= kegg_file.replace('_', ':').replace('.txt', '') )
    
    # parsing gene entry
    r_text_list = r_text.split('\n')

    # Some files may not contain all sections so this list needs to be created for each file
    section_names = [r_text_list[i][0:12].strip() for i in range(len(r_text_list)) ]
    section_names = [e for e in section_names if e != '']

    section_starts = [
        [i for i in range(len(r_text_list)) if re.match('^'+e, r_text_list[i])][0] 
        for e in section_names]

    # just split each file into text of it's sections
    out = {}

    # get lines associated with section
    def _get_section_text(section_name = 'AASEQ'):
        idx = section_names.index(section_name)
        section_text = r_text_list[section_starts[idx]:section_starts[idx+1]]
        # remove leading indent
        section_text = [e[12:] for e in section_text]
        return(section_text)

    for section_name in section_names:
        if section_name != '///': # end of file
            out[section_name] = _get_section_text(section_name = section_name)

    return(out)

save_dir = '../data/zma/kegg/'
save_path = save_dir+'cached_kegg_gene_files.pkl'

ensure_dir_path_exists(dir_path = save_dir)

# 27258 zma_100037738.txt

# kegg_gene_to_dict(
#             kegg_file = 'zma_100037738.txt',
# #             encoding="ISO-8859-1"
#         )

# kegg_gene_files = os.listdir('../ext_data/zma/kegg/gene_entries/')

# lst_out = []

# for i in range(len(kegg_gene_files)):
#     kegg_gene_file = kegg_gene_files[i]
#     print(i, kegg_gene_file)
#     lst_out += [    
#         kegg_gene_to_dict(
#             kegg_file = kegg_gene_file,
#             encoding="ISO-8859-1"
#         )]

if not os.path.exists(save_path):
    # This is a pain. I would like to parallelize reading these files in, but since it only has to be done once per species doing so would be premature optimization.
    # BUT it seems that nbdev is rerunning it as part of the CI workflow. So caching it makes sense. 
    kegg_gene_files = os.listdir('../ext_data/zma/kegg/gene_entries/')
#     kegg_gene_entries = [kegg_gene_to_dict(kegg_file = kegg_gene_file) for kegg_gene_file in tqdm.tqdm(kegg_gene_files)]
    kegg_gene_entries = [kegg_gene_to_dict(
        kegg_file = kegg_gene_file,
        encoding="ISO-8859-1"
    ) for kegg_gene_file in kegg_gene_files]
    # 37712/37712 [07:12<00:00, 87.23it/s]

    with open(save_path, 'wb') as handle:
        pkl.dump(kegg_gene_entries, 
                 handle, 
                 protocol=pkl.HIGHEST_PROTOCOL)
else:
    # Reading in data
    with open(save_path, 'rb') as handle:
        kegg_gene_entries = pkl.load(handle)

# produce a flat list of keys then deduplicate them
kegg_gene_sections = [entry for sublist in [list(kegg_gene_entries[i].keys()) for i in range(len(kegg_gene_entries))] 
                  for entry in sublist] # entry is defined here so without it the list comprehension fails instead of producing the list of sublists
kegg_gene_sections = list(set(kegg_gene_sections))
kegg_gene_sections 

# Helper Functions ---------------------------------------------------------------------
# helper fcn to pull indices and examples of sections
def get_section_examples(section = 'MOTIF', n = 5):
    i_section_matches = [i for i in range(len(kegg_gene_entries)) if section in kegg_gene_entries[i].keys()]
    out = [[i_section_matches[i], 
            kegg_gene_entries[i_section_matches[i]][section] ] for i in range(n)]
    return(out)

get_section_examples(section = 'SYMBOL', n = 5)

# Any non-hierarical list of attributes can go here. It will be transformed into a dict
def _gene_entry_flat_list(section_entry):
    # split like so [['NCBI-GeneID', '103644366'], ['NCBI-ProteinID', 'XP_020400304']]
    # then convert to dict
    # {'NCBI-GeneID': '103644366', 'NCBI-ProteinID': 'XP_020400304'}
    section_entry = [e.replace(section_name, '').strip().split(': ') for e in section_entry]
    section_entry = dict(section_entry)
    return(section_entry)

# 'AASEQ', 'NTSEQ'
def _gene_seq_to_dict(seq_list):
    out = {}
    out['lenght'] = int(seq_list[0])
    out['seq'] = ''.join(seq_list[1:])
    return(out)



# Figuring out how to process BRITE entries
kegg_gene_entry = kegg_gene_entries[0]
section_entry = kegg_gene_entry['BRITE']

section_entry

# get the leading whitespace for each line
indent_spaces = [re.findall('^ +', e)[0] if re.match('^ ', e) else [''][0] for e in section_entry]
indent_spaces = [len(e) for e  in indent_spaces]

len(indent_spaces), indent_spaces

i = 4 # position in list
indent = indent_spaces[i] # indent at that position

j = i
current_indent = indent
# work backawards to get the paths
j_backtrack      = [j]
indent_backtrack = [current_indent]

while indent_backtrack[-1] > 0:
    while current_indent != indent_backtrack[-1]-1:
        j = j-1
        current_indent = indent_spaces[j]

    j_backtrack.extend([j])
    indent_backtrack.extend([current_indent])

    # indent
    print(j_backtrack, indent_backtrack) # 

def _indent_backtrack_path(i, # position in list 
                           indent_spaces                                        
                          ):
    indent = indent_spaces[i] # indent at that position
    j = i
    current_indent = indent
    # work backawards to get the paths
    j_backtrack      = [j]
    indent_backtrack = [current_indent]

    while indent_backtrack[-1] > 0:
        while current_indent != indent_backtrack[-1]-1:
            j = j-1
            current_indent = indent_spaces[j]

        j_backtrack.extend([j])
        indent_backtrack.extend([current_indent])
        
    # indent_backtrack is not needed beyond debugging
    # confirm that the indent only decreases as you walk through the backtrack
    indent_check = indent_backtrack[1:]+[-1]
    indent_check =  [True if indent_backtrack[i] > indent_check[i] else False for i in range(len(indent_backtrack))]
    assert False not in indent_check
    
    return(j_backtrack)

def _gene_entry_BRITE(section_entry):
    # get the leading whitespace for each line
    indent_spaces = [re.findall('^ +', e)[0] if re.match('^ ', e) else [''][0] for e in section_entry]
    indent_spaces = [len(e) for e  in indent_spaces]

    # find the leaves
    # ['KEGG Orthology (KO) [BR:zma00001]',
    #  ' 09120 Genetic Information Processing',
    #  '  09121 Transcription',
    #  '   03020 RNA polymerase',
    #  '    100037782' <------------- Whitespace followed by digits and no letters
    leaf_idxs = [i for i in range(len(section_entry)) if re.match('^\s+\d+$', section_entry[i])]

    # for each leaf get the backtrack path to the root
    leaf_backtraces = [_indent_backtrack_path(i = leaf_idx, 
                                              indent_spaces = indent_spaces
                                             ) for leaf_idx in leaf_idxs]
    # reverse the inner lists
    [e.reverse()  for e in leaf_backtraces]

    out = [[section_entry[i] for i in leaf_backtraces[j]] for j in range(len(leaf_backtraces))]
    # sample input
    # ['KEGG Orthology (KO) [BR:zma00001]',
    #  ' 09120 Genetic Information Processing',
    #  '  09121 Transcription',
    #  '   03020 RNA polymerase',
    #  '    100037782',
    #  ' 09180 Brite Hierarchies',
    #  '  09182 Protein families: genetic information processing',
    #  '   03021 Transcription machinery [BR:zma03021]',
    #  '    100037782',
    #  'Enzymes [BR:zma01000]',
    #  ' 2. Transferases',
    #  '  2.7  Transferring phosphorus-containing groups',
    #  '   2.7.7  Nucleotidyltransferases',
    #  '    2.7.7.6  DNA-directed RNA polymerase',
    #  '     100037782',
    #  'Transcription machinery [BR:zma03021]',
    #  ' Eukaryotic type',
    #  '  RNA polymerase II system',
    #  '   RNA polymerase II',
    #  '    Pol IV and V specific subunits',
    #  '     100037782']

    # Sample output
    # [['KEGG Orthology (KO) [BR:zma00001]',
    #   ' 09120 Genetic Information Processing',
    #   '  09121 Transcription',
    #   '   03020 RNA polymerase',
    #   '    100037782'],
    #  ['KEGG Orthology (KO) [BR:zma00001]',
    #   ' 09180 Brite Hierarchies',
    #   '  09182 Protein families: genetic information processing',
    #   '   03021 Transcription machinery [BR:zma03021]',
    #   '    100037782'],
    #  ['Enzymes [BR:zma01000]',
    #   ' 2. Transferases',
    #   '  2.7  Transferring phosphorus-containing groups',
    #   '   2.7.7  Nucleotidyltransferases',
    #   '    2.7.7.6  DNA-directed RNA polymerase',
    #   '     100037782'],
    #  ['Transcription machinery [BR:zma03021]',
    #   ' Eukaryotic type',
    #   '  RNA polymerase II system',
    #   '   RNA polymerase II',
    #   '    Pol IV and V specific subunits',
    #   '     100037782']]

    # and then strip whitespace
    out = [[ee.strip() for ee in e] for e in out]
    return(out)

def parse_kegg_gene_entry(kegg_gene_entry):
    for section in kegg_gene_entry.keys():
        if type(kegg_gene_entry[section]) != list :
            # This is a safeguard to prevent the code from breaking when rerun. All entries start out as list
            # so if an entry isn't a list then it's already been transformed
            pass

        else:
            if section in ['TEMPLATE']:
                kegg_gene_entry[section] = kegg_gene_entry[section]

            elif section in ['ENTRY', 'NAME', 'ORTHOLOGY', 'ORGANISM', 'POSITION', 'SYMBOL', 'STRUCTURE']:
                kegg_gene_entry[section] = kegg_gene_entry[section][0]

            elif section in ['PATHWAY', 'MODULE']: 
                # NOTE: PATHWAY contains two spaces between the identifier and name which is why I'm not splitting on the first instance of whitespace.
                # 'zma00591  Linoleic acid metabolism'
                #          ^^        ^    ^
                kegg_gene_entry[section] = dict([e.split('  ') for e in kegg_gene_entry[section]])            

            elif section in ['BRITE']:
                # This dict is only expected to have a single key. Representing these data as a dict allows for the 
                # list checking logic above to still work.
                kegg_gene_entry[section] = {"BRITE_PATHS": _gene_entry_BRITE(section_entry = kegg_gene_entry[section])}

#             elif section in ['MODULE']:
#                 pass
#                 kegg_gene_entry[section] = _gene_entry_flat_list(section_entry=kegg_gene_entry[section])
                
            elif section in ['MOTIF', 'DBLINKS']:
                kegg_gene_entry[section] = _gene_entry_flat_list(section_entry=kegg_gene_entry[section])

            elif section in ['AASEQ', 'NTSEQ']:
                kegg_gene_entry[section] = _gene_seq_to_dict(seq_list = kegg_gene_entry[section])

            else:
                print("No behavior defined for "+section)

    return(kegg_gene_entry)

parsed_kegg_gene_entries = [parse_kegg_gene_entry(kegg_gene_entry = kegg_gene_entry
#                                                  ) for kegg_gene_entry in tqdm.tqdm(kegg_gene_entries)]
                                                 ) for kegg_gene_entry in kegg_gene_entries]

save_dir = '../data/zma/kegg/'

ensure_dir_path_exists(dir_path = '../data/zma/kegg/')

with open(save_dir+'kegg_gene_entries.pkl', 'wb') as handle:
    pkl.dump(parsed_kegg_gene_entries, 
             handle, 
             protocol=pkl.HIGHEST_PROTOCOL)
    
# Reading in data
# with open('./data/kegg_gene_entries.pkl', 'rb') as handle:
#     kegg_gene_entries = pkl.load(handle)

# Restrict to only those with pathway
kegg_gene_brite = [e for e in parsed_kegg_gene_entries if 'BRITE' in e.keys()]

i = 0
is_list = []
for i in range(len(kegg_gene_brite)):
    js_list = []
    for j in range(len(kegg_gene_brite[i]['BRITE']['BRITE_PATHS'])): 
        entries_path = kegg_gene_brite[i]['BRITE']['BRITE_PATHS'][j]
        if entries_path != []:
        
            temp = pd.DataFrame(entries_path)
            temp = temp.T
            temp['ENTRY'] = kegg_gene_brite[i]['ENTRY']+'_'+str(j)
            
            js_list = js_list + [temp]
            
    if js_list != []:
        is_list = is_list + [pd.concat(js_list)]
    

# is_list

BRITE_df = pd.concat(is_list)

BRITE_df = BRITE_df.drop_duplicates().reset_index().drop(columns = 'index')
BRITE_df

#TODO find out what is causing levels deeper than 3 or the indices below (and others) to fail
fig = px.treemap(BRITE_df.loc[:
#     (
#     (BRITE_df.index != 7480) &
#     (BRITE_df.index != 8131) &
#     (BRITE_df.index != 8838) &
#     (BRITE_df.index != 8837) &
#     (BRITE_df.index != 8836)
# )
    , :], path=[px.Constant("all"), 0, 1, 2, 3, #4, 5, 6
            ], 
#                  values='a'
                )
fig.update_traces(root_color="lightgrey")
fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))
fig.show()

#| hide
import nbdev; nbdev.nbdev_export()
