{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7219b3",
   "metadata": {},
   "source": [
    "# Deep Learning Convenience Functions\n",
    "\n",
    "> This notebook contains convenience functions to aid in modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32788a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dlfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def calc_cs(x # numeric array\n",
    "           ): \n",
    "    \"Calculate nan mean and nan std of an array. Returned as list\"\n",
    "    import numpy as np\n",
    "    return [np.nanmean(x, axis = 0), np.nanstd(x, axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def apply_cs(xs, \n",
    "             cs_dict_entry # list of length 2 containing mean and s\n",
    "            ): return ((xs - cs_dict_entry[0]) / cs_dict_entry[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9321aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def reverse_cs(xs, cs_dict_entry): return (cs_dict_entry[1] * xs) + cs_dict_entry[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e02222",
   "metadata": {},
   "source": [
    "## Boilerplate Functions for Tian et al 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "#     import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "#     from torch import nn\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TianEtAl2011Dataset(Dataset):    \n",
    "    def __init__(self, \n",
    "                 y1, y2, y3, #xs, \n",
    "                 idx_original,\n",
    "                 marker_type = 'markers',\n",
    "                 transform = None, target_transform = None,\n",
    "                 use_gpu_num = 0,\n",
    "                 **kwargs # use to allow for cpu to be passed into function \n",
    "                \n",
    "                ):\n",
    "        \n",
    "        if 'device' in kwargs.keys():\n",
    "            pass\n",
    "        else:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            if use_gpu_num in [0, 1]: \n",
    "                torch.cuda.set_device(use_gpu_num)\n",
    "                \n",
    "        print(f\"Using {device} device\")\n",
    "        self.device = device\n",
    "\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.y3 = y3\n",
    "        self.idx_original = idx_original\n",
    "        self.marker_type = marker_type\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y1_idx = self.y1[idx].to(self.device).float()\n",
    "        y2_idx = self.y2[idx].to(self.device).float()\n",
    "        y3_idx = self.y3[idx].to(self.device).float()\n",
    "        \n",
    "        \n",
    "        # Change type of xs loaded !! ----------------------------------------\n",
    "        if self.marker_type == 'markers':        \n",
    "            # Non-Hilbert Version\n",
    "            save_path = '../models/10_TianEtAl2011/markers/'\n",
    "            save_file_path = save_path+'m'+str(int(self.idx_original[idx]))+'.npz'\n",
    "            xs_idx = np.load(save_file_path)['arr_0']\n",
    "            xs_idx = torch.from_numpy(xs_idx).to(self.device).float()\n",
    "            xs_idx = xs_idx.squeeze()\n",
    "            # to match pytorch's conventions channel must be in the second dim\n",
    "            xs_idx = torch.swapaxes(xs_idx, 0, 1) \n",
    "            \n",
    "        elif self.marker_type == 'hilbert':\n",
    "            # Hilbert version\n",
    "            save_path = '../models/10_TianEtAl2011/hilbert/'\n",
    "            save_file_path = save_path+'h'+str(int(self.idx_original[idx]))+'.npz'\n",
    "            xs_idx = np.load(save_file_path)['arr_0']\n",
    "            # there are missing values in the hilbert curve. Set these to 0\n",
    "            xs_idx[np.isnan(xs_idx)] = 0\n",
    "            \n",
    "            xs_idx = torch.from_numpy(xs_idx).to(self.device).float()\n",
    "            xs_idx = xs_idx.squeeze()\n",
    "            \n",
    "            # to match pytorch's conventions channel must be in the second dim\n",
    "            xs_idx = torch.swapaxes(xs_idx, 1, 2) \n",
    "            xs_idx = torch.swapaxes(xs_idx, 0, 1)    \n",
    "            \n",
    "            \n",
    "        \n",
    "        if self.transform:\n",
    "            xs_idx = self.transform(xs_idx)\n",
    "            \n",
    "        if self.target_transform:\n",
    "            y1_idx = self.transform(y1_idx)\n",
    "            y2_idx = self.transform(y2_idx)\n",
    "            y3_idx = self.transform(y3_idx)\n",
    "        return xs_idx, y1_idx, y2_idx, y3_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c81883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, silent = False):\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "#     from torch import nn\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (xs_i, y1_i, y2_i, y3_i) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(xs_i)\n",
    "        loss = loss_fn(pred, y1_i) # <----------------------------------------\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(y1_i) # <----------------\n",
    "            if not silent:\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef067bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def train_error(dataloader, model, loss_fn, silent = False):\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "#     from torch import nn\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xs_i, y1_i, y2_i, y3_i in dataloader:\n",
    "            pred = model(xs_i)\n",
    "            train_loss += loss_fn(pred, y1_i).item() # <----------------------\n",
    "            \n",
    "    train_loss /= num_batches\n",
    "    return(train_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, silent = False):\n",
    "#     import numpy as np\n",
    "#     import pandas as pd\n",
    "    import torch\n",
    "    from torch.utils.data import Dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "#     from torch import nn\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xs_i, y1_i, y2_i, y3_i in dataloader:\n",
    "            pred = model(xs_i)\n",
    "            test_loss += loss_fn(pred, y1_i).item() # <-----------------------\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    if not silent:\n",
    "        print(f\"Test Error: Avg loss: {test_loss:>8f}\")\n",
    "    return(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c78817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def train_nn(\n",
    "    nb_name,\n",
    "    training_dataloader,\n",
    "    testing_dataloader,\n",
    "    model,\n",
    "    learning_rate = 1e-3,\n",
    "    batch_size = 64,\n",
    "    epochs = 500\n",
    "):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "#     from torch.utils.data import Dataset\n",
    "#     from torch.utils.data import DataLoader\n",
    "    from torch import nn\n",
    "    \n",
    "    # Initialize the loss function\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_df = pd.DataFrame([i for i in range(epochs)], columns = ['Epoch'])\n",
    "    loss_df['TrainMSE'] = np.nan\n",
    "    loss_df['TestMSE']  = np.nan\n",
    "\n",
    "    for t in tqdm(range(epochs)):        \n",
    "        # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(training_dataloader, model, loss_fn, optimizer, silent = True)\n",
    "\n",
    "        loss_df.loc[loss_df.index == t, 'TrainMSE'\n",
    "                   ] = train_error(training_dataloader, model, loss_fn, silent = True)\n",
    "        \n",
    "        loss_df.loc[loss_df.index == t, 'TestMSE'\n",
    "                   ] = test_loop(testing_dataloader, model, loss_fn, silent = True)\n",
    "        \n",
    "        if (t+1)%5 == 0: # Cache in case training is interupted. \n",
    "            # print(loss_df.loc[loss_df.index == t, ['TrainMSE', 'TestMSE']])\n",
    "            torch.save(model.state_dict(), \n",
    "                       '../models/'+nb_name+'/model_'+str(t)+'_'+str(epochs)+'.pt') # convention is to use .pt or .pth\n",
    "        \n",
    "    return([model, loss_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6745d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def yhat_loop(dataloader, model):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "#     from torch.utils.data import Dataset\n",
    "#     from torch.utils.data import DataLoader\n",
    "#     from torch import nn\n",
    "\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xs_i, y1_i, y2_i, y3_i in dataloader:\n",
    "            yhat_i = model(xs_i)\n",
    "            y_i = y1_i # <-----------------------\n",
    "            y_pred = np.append(y_pred, np.array(yhat_i.cpu()))\n",
    "            y_true = np.append(y_true, np.array(y_i.cpu()))\n",
    "    \n",
    "    out = np.concatenate([y_true[:, None], y_pred[:, None]], axis = 1) \n",
    "    out = pd.DataFrame(out, columns = ['y_true', 'y_pred'])\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ace40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e9eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680915b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8421f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
