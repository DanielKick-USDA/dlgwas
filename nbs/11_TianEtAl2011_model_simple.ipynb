{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e9456e3",
   "metadata": {},
   "source": [
    "# Tian et al. 2011 Model 1\n",
    "\n",
    "> This series of notebooks aims to reproduce the findings of *Tian et al. 2011*, \"Genome-wide association study of leaf architecture in the maize nested association mapping population\". The goal is to build progressively more complex models, identify good performance, then look at feature importantce in good performing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de638fa",
   "metadata": {},
   "source": [
    "<!-- It used data from panzea\n",
    "- Phenotypic data panzea\\phenotypes\\Buckler_etal_2009_Science_flowering_time_data-090807\\\n",
    "- Genotypic Data panzea\\genotypes\\GBS\\v27\\ZeaGBSv27_publicSamples_imputedV5_AGPv4-181023.vcf.gz\n",
    "- Genomic Data ...  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9efb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacky way to schedule. Here I'm setting these to sleep until the gpus should be free.\n",
    "# At the end of the notebooks  os._exit(00) will kill the kernel freeing the gpu. \n",
    "#                          Hours to wait\n",
    "# import time; time.sleep( (18*2) * (60*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268d3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Run Settings:\n",
    "nb_name = '11_TianEtAl2011'# Set manually! -----------------------------------\n",
    "\n",
    "downsample_obs = False\n",
    "train_n = 90\n",
    "test_n = 10\n",
    "\n",
    "dataloader_batch_size = 64\n",
    "run_epochs = 200\n",
    "\n",
    "use_gpu_num = 1\n",
    "\n",
    "# Imports --------------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "import dlgwas\n",
    "from dlgwas.kegg import ensure_dir_path_exists\n",
    "from dlgwas.kegg import get_cached_result\n",
    "from dlgwas.kegg import put_cached_result\n",
    "\n",
    "from dlgwas.dlfn import calc_cs\n",
    "from dlgwas.dlfn import apply_cs\n",
    "from dlgwas.dlfn import reverse_cs\n",
    "\n",
    "from dlgwas.dlfn import TianEtAl2011Dataset\n",
    "from dlgwas.dlfn import train_loop\n",
    "from dlgwas.dlfn import train_error\n",
    "from dlgwas.dlfn import test_loop\n",
    "from dlgwas.dlfn import train_nn\n",
    "from dlgwas.dlfn import yhat_loop\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if use_gpu_num in [0, 1]: \n",
    "    torch.cuda.set_device(use_gpu_num)\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir_path_exists(dir_path = '../models/'+nb_name)\n",
    "ensure_dir_path_exists(dir_path = '../reports/'+nb_name)\n",
    "\n",
    "ensure_dir_path_exists(dir_path = '../models/'+nb_name)\n",
    "ensure_dir_path_exists(dir_path = '../reports/'+nb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a8cf4",
   "metadata": {},
   "source": [
    "##  Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31481b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned data\n",
    "taxa_groupings = pd.read_csv('../models/10_TianEtAl2011/taxa_groupings.csv')\n",
    "data           = pd.read_csv('../models/10_TianEtAl2011/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2001130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 Unique Holdout Groups.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sample</th>\n",
       "      <th>Population</th>\n",
       "      <th>Holdout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Z001E0001</td>\n",
       "      <td>B73 x B97</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Z001E0002</td>\n",
       "      <td>B73 x B97</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Z001E0003</td>\n",
       "      <td>B73 x B97</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Z001E0004</td>\n",
       "      <td>B73 x B97</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Z001E0005</td>\n",
       "      <td>B73 x B97</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>4671</td>\n",
       "      <td>Z026E0196</td>\n",
       "      <td>B73 x Tzi8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>4672</td>\n",
       "      <td>Z026E0197</td>\n",
       "      <td>B73 x Tzi8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>4673</td>\n",
       "      <td>Z026E0198</td>\n",
       "      <td>B73 x Tzi8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>4674</td>\n",
       "      <td>Z026E0199</td>\n",
       "      <td>B73 x Tzi8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>4675</td>\n",
       "      <td>Z026E0200</td>\n",
       "      <td>B73 x Tzi8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4676 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     sample  Population Holdout\n",
       "0              0  Z001E0001   B73 x B97      22\n",
       "1              1  Z001E0002   B73 x B97      22\n",
       "2              2  Z001E0003   B73 x B97      22\n",
       "3              3  Z001E0004   B73 x B97      22\n",
       "4              4  Z001E0005   B73 x B97      22\n",
       "...          ...        ...         ...     ...\n",
       "4671        4671  Z026E0196  B73 x Tzi8      19\n",
       "4672        4672  Z026E0197  B73 x Tzi8      19\n",
       "4673        4673  Z026E0198  B73 x Tzi8      19\n",
       "4674        4674  Z026E0199  B73 x Tzi8      19\n",
       "4675        4675  Z026E0200  B73 x Tzi8      19\n",
       "\n",
       "[4676 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define holdout sets (Populations)\n",
    "uniq_pop = list(set(taxa_groupings['Population']))\n",
    "print(str(len(uniq_pop))+\" Unique Holdout Groups.\")\n",
    "taxa_groupings['Holdout'] = None\n",
    "for i in range(len(uniq_pop)):\n",
    "    mask = (taxa_groupings['Population'] == uniq_pop[i])\n",
    "    taxa_groupings.loc[mask, 'Holdout'] = i\n",
    "\n",
    "taxa_groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c685f85",
   "metadata": {},
   "source": [
    "## Setup Holdouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly holdout a population if there is not a file with the population held out.\n",
    "# Holdout_Int = 0\n",
    "Holdout_Int_path = '../models/'+nb_name+'/holdout_pop_int.pkl'\n",
    "if None != get_cached_result(Holdout_Int_path):\n",
    "    Holdout_Int = get_cached_result(Holdout_Int_path)\n",
    "else:\n",
    "    Holdout_Int = int(np.random.choice([i for i in range(len(uniq_pop))], 1))\n",
    "    put_cached_result(Holdout_Int_path, Holdout_Int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holding out i=22: B73 x B97\n"
     ]
    }
   ],
   "source": [
    "print(\"Holding out i=\"+str(Holdout_Int)+\": \"+uniq_pop[Holdout_Int])\n",
    "\n",
    "mask = (taxa_groupings['Holdout'] == Holdout_Int)\n",
    "train_idxs = list(taxa_groupings.loc[~mask, ].index)\n",
    "test_idxs = list(taxa_groupings.loc[mask, ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571cbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[193, 4483]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(e) for e in [test_idxs, train_idxs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93273048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample_obs = True\n",
    "# train_n = 900\n",
    "# test_n = 100\n",
    "\n",
    "if downsample_obs == True:\n",
    "    train_idxs = np.random.choice(train_idxs, train_n)\n",
    "    test_idxs = np.random.choice(test_idxs, test_n)\n",
    "    print([len(e) for e in [test_idxs, train_idxs]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to go from index in tensor to index in data so that the right xs tensor can be loaded in\n",
    "idx_original = np.array(data.index)\n",
    "\n",
    "y1 = data['leaf_length']\n",
    "y2 = data['leaf_width']\n",
    "y3 = data['upper_leaf_angle']\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96baeb0b",
   "metadata": {},
   "source": [
    "### Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_dict_path = '../models/'+nb_name+'/scale_dict.pkl'\n",
    "if None != get_cached_result(scale_dict_path):\n",
    "    scale_dict = get_cached_result(scale_dict_path)\n",
    "else:\n",
    "    scale_dict = {\n",
    "        'y1':calc_cs(y1[train_idxs]),\n",
    "        'y2':calc_cs(y2[train_idxs]),\n",
    "        'y3':calc_cs(y3[train_idxs])\n",
    "    }\n",
    "    put_cached_result(scale_dict_path, scale_dict)\n",
    "\n",
    "y1 = apply_cs(y1, scale_dict['y1'])\n",
    "y2 = apply_cs(y2, scale_dict['y2'])\n",
    "y3 = apply_cs(y3, scale_dict['y3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c62560",
   "metadata": {},
   "source": [
    "## Allow for cycling data onto and off of GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4963d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading this into memory causes the session to crash\n",
    "\n",
    "y1_train = torch.from_numpy(y1[train_idxs])[:, None]\n",
    "y2_train = torch.from_numpy(y2[train_idxs])[:, None]\n",
    "y3_train = torch.from_numpy(y3[train_idxs])[:, None]\n",
    "\n",
    "idx_original_train = torch.from_numpy(idx_original[train_idxs])\n",
    "\n",
    "y1_test = torch.from_numpy(y1[test_idxs])[:, None]\n",
    "y2_test = torch.from_numpy(y2[test_idxs])[:, None]\n",
    "y3_test = torch.from_numpy(y3[test_idxs])[:, None]\n",
    "\n",
    "idx_original_test = torch.from_numpy(idx_original[test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# dataloader_batch_size = 64\n",
    "\n",
    "training_dataloader = DataLoader(\n",
    "    TianEtAl2011Dataset(\n",
    "                  y1 =           y1_train,\n",
    "                  y2 =           y2_train,\n",
    "                  y3 =           y3_train,\n",
    "        idx_original = idx_original_train,\n",
    "         use_gpu_num = use_gpu_num,\n",
    "#         device = 'cpu'\n",
    "    ), \n",
    "    batch_size = dataloader_batch_size, \n",
    "    shuffle = True)\n",
    "\n",
    "testing_dataloader = DataLoader(\n",
    "    TianEtAl2011Dataset(\n",
    "                  y1 =           y1_test,\n",
    "                  y2 =           y2_test,\n",
    "                  y3 =           y3_test,\n",
    "        idx_original = idx_original_test,\n",
    "         use_gpu_num = use_gpu_num,\n",
    "#         device = 'cpu'\n",
    "    ), \n",
    "    batch_size = dataloader_batch_size, \n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0e595",
   "metadata": {},
   "source": [
    "## Non-Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_i, y1_i, y2_i, y3_i = next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del training_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xs_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83274f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()    \n",
    "        self.x_network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3773820, 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out = self.x_network(x)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3945e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork().to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f7a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30360ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(xs_i)[0:3] # try prediction on one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_loop(dataloader, model, loss_fn, optimizer, silent = False):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     for batch, (xs_i, y1_i, y2_i, y3_i) in enumerate(dataloader):\n",
    "#         # Compute prediction and loss\n",
    "#         pred = model(xs_i)\n",
    "#         loss = loss_fn(pred, y1_i) # <----------------------------------------\n",
    "\n",
    "#         # Backpropagation\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if batch % 100 == 0:\n",
    "#             loss, current = loss.item(), batch * len(y1_i) # <----------------\n",
    "#             if not silent:\n",
    "#                 print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "                \n",
    "# def train_error(dataloader, model, loss_fn, silent = False):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     train_loss = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for xs_i, y1_i, y2_i, y3_i in dataloader:\n",
    "#             pred = model(xs_i)\n",
    "#             train_loss += loss_fn(pred, y1_i).item() # <----------------------\n",
    "            \n",
    "#     train_loss /= num_batches\n",
    "#     return(train_loss) \n",
    "\n",
    "            \n",
    "# def test_loop(dataloader, model, loss_fn, silent = False):\n",
    "#     size = len(dataloader.dataset)\n",
    "#     num_batches = len(dataloader)\n",
    "#     test_loss = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for xs_i, y1_i, y2_i, y3_i in dataloader:\n",
    "#             pred = model(xs_i)\n",
    "#             test_loss += loss_fn(pred, y1_i).item() # <-----------------------\n",
    "\n",
    "#     test_loss /= num_batches\n",
    "#     if not silent:\n",
    "#         print(f\"Test Error: Avg loss: {test_loss:>8f}\")\n",
    "#     return(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd307ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_nn(\n",
    "#     training_dataloader,\n",
    "#     testing_dataloader,\n",
    "#     model,\n",
    "#     learning_rate = 1e-3,\n",
    "#     batch_size = 64,\n",
    "#     epochs = 500\n",
    "# ):\n",
    "#     # Initialize the loss function\n",
    "#     loss_fn = nn.MSELoss()\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     loss_df = pd.DataFrame([i for i in range(epochs)], columns = ['Epoch'])\n",
    "#     loss_df['TrainMSE'] = np.nan\n",
    "#     loss_df['TestMSE']  = np.nan\n",
    "\n",
    "#     for t in tqdm(range(epochs)):        \n",
    "# #         print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#         train_loop(training_dataloader, model, loss_fn, optimizer, silent = True)\n",
    "\n",
    "#         loss_df.loc[loss_df.index == t, 'TrainMSE'\n",
    "#                    ] = train_error(training_dataloader, model, loss_fn, silent = True)\n",
    "        \n",
    "#         loss_df.loc[loss_df.index == t, 'TestMSE'\n",
    "#                    ] = test_loop(testing_dataloader, model, loss_fn, silent = True)\n",
    "        \n",
    "#         if (t+1)%10: # Cache in case training is interupted\n",
    "# #             print(loss_df.loc[loss_df.index == t, ['TrainMSE', 'TestMSE']])\n",
    "#             torch.save(model.state_dict(), \n",
    "#                        '../models/'+nb_name+'/model_'+str(t)+'_'+str(epochs)+'.pt') # convention is to use .pt or .pth\n",
    "        \n",
    "#     return([model, loss_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d278002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't run if either of these exist because there may be cases where we want the results but not the model\n",
    "\n",
    "# if not os.path.exists('../models/'+nb_name+'/model.pt'): \n",
    "#     model = NeuralNetwork().to(device)\n",
    "\n",
    "#     model, loss_df = train_nn(\n",
    "#         nb_name,\n",
    "#         training_dataloader,\n",
    "#         testing_dataloader,\n",
    "#         model,\n",
    "#         learning_rate = 1e-3,\n",
    "#         batch_size = dataloader_batch_size,\n",
    "#         epochs = run_epochs\n",
    "#     )\n",
    "    \n",
    "#     # experimental outputs:\n",
    "#     # 1. Model\n",
    "#     torch.save(model.state_dict(), '../models/'+nb_name+'/model.pt') # convention is to use .pt or .pth\n",
    "\n",
    "#     # 2. loss_df\n",
    "#     loss_df.to_csv('../reports/'+nb_name+'/loss_df.csv', index=False)  \n",
    "    \n",
    "    \n",
    "#     # 3. predictions \n",
    "#     yhats = pd.concat([\n",
    "#         yhat_loop(testing_dataloader, model).assign(Split = 'Test'),\n",
    "#         yhat_loop(training_dataloader, model).assign(Split = 'Train')], axis = 0)\n",
    "\n",
    "#     yhats.to_csv('../reports/'+nb_name+'/yhats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Training: 52/200 epochs run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                        | 111/148 [8:19:21<2:44:55, 267.44s/it]"
     ]
    }
   ],
   "source": [
    "# don't run if either of these exist because there may be cases where we want the results but not the model\n",
    "\n",
    "if not os.path.exists('../models/'+nb_name+'/model.pt'): \n",
    "    # Shared setup (train from scratch and load latest)\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    # find the biggest model to save\n",
    "    saved_models = os.listdir('../models/'+nb_name+'/')\n",
    "    saved_models = [e for e in saved_models if re.match('model*', e)]\n",
    "\n",
    "    if saved_models == []:\n",
    "        epochs_run = 0\n",
    "    else:\n",
    "        # if there are saved models reload and resume training\n",
    "        saved_models_numbers = [int(e.replace('model_', ''\n",
    "                                    ).replace('.pt', ''\n",
    "                                    ).split('_')[0]) for e in saved_models]\n",
    "        # saved_models\n",
    "        epochs_run = max(saved_models_numbers)+1 # add 1 to account for 0 index\n",
    "        latest_model = [e for e in saved_models if re.match(\n",
    "            '^model_'+str(epochs_run-1)+'_.*\\.pt$', e)][0] # subtract 1 to convert back\n",
    "        model.load_state_dict(torch.load('../models/'+nb_name+'/'+latest_model))\n",
    "        print('Resuming Training: '+str(epochs_run)+'/'+str(run_epochs)+' epochs run.')\n",
    "    \n",
    "    model.to(device)\n",
    "#     model = NeuralNetwork().to(device)\n",
    "\n",
    "    model, loss_df = train_nn(\n",
    "        nb_name,\n",
    "        training_dataloader,\n",
    "        testing_dataloader,\n",
    "        model,\n",
    "        learning_rate = 1e-3,\n",
    "        batch_size = dataloader_batch_size,\n",
    "        epochs = (run_epochs - epochs_run)\n",
    "    )\n",
    "    \n",
    "    # experimental outputs:\n",
    "    # 1. Model\n",
    "    torch.save(model.state_dict(), '../models/'+nb_name+'/model.pt') # convention is to use .pt or .pth\n",
    "\n",
    "    # 2. loss_df\n",
    "    loss_df.to_csv('../reports/'+nb_name+'/loss_df.csv', index=False)  \n",
    "    \n",
    "    # 3. predictions \n",
    "    yhats = pd.concat([\n",
    "        yhat_loop(testing_dataloader, model).assign(Split = 'Test'),\n",
    "        yhat_loop(training_dataloader, model).assign(Split = 'Train')], axis = 0)\n",
    "\n",
    "    yhats.to_csv('../reports/'+nb_name+'/yhats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bca207",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3db83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_df = train_nn(\n",
    "#     training_dataloader,\n",
    "#     testing_dataloader,\n",
    "#     model,\n",
    "#     learning_rate = 1e-3,\n",
    "#     batch_size = 64,\n",
    "#     epochs = 1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # don't run if either of these exist because there may be cases where we want the results but not the model\n",
    "# #| os.path.exists('../reports/'+nb_name+'/loss_df.csv')\n",
    "\n",
    "# if not os.path.exists('../models/'+nb_name+'/model.pt'): \n",
    "\n",
    "#     model, loss_df = train_nn(\n",
    "#         training_dataloader,\n",
    "#         testing_dataloader,\n",
    "#         model,\n",
    "#         learning_rate = 1e-3,\n",
    "#         batch_size = 64,\n",
    "#         epochs = 250\n",
    "#     )\n",
    "    \n",
    "#     # experimental outputs:\n",
    "#     # 1. Model\n",
    "#     torch.save(model.state_dict(), '../models/'+nb_name+'/model.pt') # convention is to use .pt or .pth\n",
    "\n",
    "#     # 2. loss_df\n",
    "#     loss_df.to_csv('../reports/'+nb_name+'/loss_df.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This uses 6650/8192 MiB Available\n",
    "# Perhaps by using a larger batch size we can increase the used amount.\n",
    "# Increasing the size of the model will require more memory so this should be monitored.\n",
    "\n",
    "# for one iteration it takes 1/1 [04:28<00:00, 268.24s/it]\n",
    "# NeuralNetwork(\n",
    "#   (x_network): Sequential(\n",
    "#     (0): Flatten(start_dim=1, end_dim=-1)\n",
    "#     (1): Linear(in_features=3773820, out_features=64, bias=True)\n",
    "#     (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (3): ReLU()\n",
    "#     (4): Linear(in_features=64, out_features=1, bias=True)\n",
    "#   )\n",
    "# )\n",
    "\n",
    "#     45/500 [3:22:20<34:19:22, 271.57s/it]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7bf81",
   "metadata": {},
   "source": [
    "## Standard Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e55e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.read_csv('../reports/'+nb_name+'/loss_df.csv')\n",
    "\n",
    "loss_df.TrainMSE = reverse_cs(loss_df.TrainMSE, scale_dict['y1'])\n",
    "loss_df.TestMSE  = reverse_cs(loss_df.TestMSE , scale_dict['y1'])\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=loss_df.Epoch, y=loss_df.TrainMSE,\n",
    "                    mode='lines', name='Train'))\n",
    "fig.add_trace(go.Scatter(x=loss_df.Epoch, y=loss_df.TestMSE,\n",
    "                    mode='lines', name='Test'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d02e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = pd.read_csv('../reports/'+nb_name+'/yhats.csv')\n",
    "\n",
    "yhats.y_true = reverse_cs(yhats.y_true, scale_dict['y1'])\n",
    "yhats.y_pred = reverse_cs(yhats.y_pred, scale_dict['y1'])\n",
    "\n",
    "px.scatter(yhats, x = 'y_true', y = 'y_pred', color = 'Split', trendline=\"ols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats['Error'] = yhats.y_true - yhats.y_pred\n",
    "\n",
    "px.histogram(yhats, x = 'Error', color = 'Split',\n",
    "             marginal=\"rug\", # can be `box`, `violin`\n",
    "             nbins= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac00959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically kill kernel after running. \n",
    "# This is a hacky way to free up _all_ space on the gpus\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232e257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
